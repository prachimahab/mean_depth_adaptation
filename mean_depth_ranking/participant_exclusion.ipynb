{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participant Exclusion\n",
    "\n",
    "There are 10 ‘attention check’ trials randomly dispersed in the experiment. On these trials participants are shown an image, but told what to respond (e.g. Click ‘1’ for this question). Participants must get 8 out of 10 attention check trials correct to be included in the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/prachimahableshwarkar/Downloads/Mean Depth Ranking Task_April 24, 2023_08.21.csv'\n",
    "\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch = {'Q336': 1, 'Q337': 1, 'Q338': 2, 'Q339': 2, 'Q340': 3, 'Q341': 3, 'Q342': 4, 'Q343': 4, 'Q344': 5, 'Q345': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StartDate',\n",
       " 'EndDate',\n",
       " 'Status',\n",
       " 'IPAddress',\n",
       " 'Progress',\n",
       " 'Duration (in seconds)',\n",
       " 'Finished',\n",
       " 'RecordedDate',\n",
       " 'ResponseId',\n",
       " 'RecipientLastName',\n",
       " 'RecipientFirstName',\n",
       " 'RecipientEmail',\n",
       " 'ExternalReference',\n",
       " 'LocationLatitude',\n",
       " 'LocationLongitude',\n",
       " 'DistributionChannel',\n",
       " 'UserLanguage']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in df.columns if 'Q' not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 'R_ei0emQmbFYFOQuJ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_ids = [rid for rid in df.ResponseId.unique() if 'R_' in rid]\n",
    "len(participant_ids), participant_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 0.6808510638297872, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = []\n",
    "nans = []\n",
    "for participant in participant_ids:\n",
    "    p_df = df.loc[df['ResponseId'] == participant]\n",
    "    num_correct = 0\n",
    "    nan = False\n",
    "    for key in catch:\n",
    "        correct_answer = catch[key]\n",
    "        try:\n",
    "            p_response = int(p_df[key].unique()[0])\n",
    "            if correct_answer == p_response:\n",
    "                num_correct += 1\n",
    "        except:\n",
    "            nan = True\n",
    "    nans.append(nan)\n",
    "            \n",
    "    if num_correct < 8:\n",
    "        exclude.append(participant)\n",
    "    \n",
    "len(exclude), len(exclude)/len(participant_ids), len([b for b in nans if b == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exclude.npy', 'wb') as f:\n",
    "    np.save(f, np.array(exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    participant = row['ResponseId']\n",
    "    if participant in exclude:\n",
    "        df = df.drop(index)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 45)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.ResponseId.unique())-2, len(participant_ids) - len(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA COLLECTION NOTES:\n",
    "\n",
    "- In V1, participants were not forced to respond to each question through Qualtrics so many questions were left unanswered. This created a llot of data loss.\n",
    "    - V1: 18/50 remained so 32 were re-posted\n",
    "- V2\n",
    "    - some responses are completely empty and not tied to SONA, possibly just bots --> these should be removed from the count when reporting data loss in the paper\n",
    "\n",
    "\n",
    "\n",
    "batch1 = 50\n",
    "\n",
    "batch2 = 32\n",
    "\n",
    "batch3 = 18\n",
    "\n",
    "batch4 = 20 \n",
    "\n",
    "batch5 = 5, but 10 were posted to get ahead of data loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
